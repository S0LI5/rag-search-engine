# Knowledge-Base Search Engine with RAG

This project is a powerful, local-first search engine that uses Retrieval-Augmented Generation (RAG) to answer questions about your own documents. You can upload PDFs, and the application will use a Large Language Model (LLM) to provide accurate, synthesized answers complete with source citations.

The project provides two user-friendly graphical interfaces (Streamlit and Gradio), along with robust command-line utilities for managing the knowledge base.

## 🌟 Features

* **Document Ingestion**: Upload PDF documents directly through the web UI to build your knowledge base.
* **AI-Powered Q&A**: Ask questions in natural language and receive synthesized answers generated by an LLM.
* **Verifiable Sources**: Every answer is backed by citations from the source documents, including page numbers and relevance scores, to prevent hallucinations and ensure accuracy.
* **Dual UIs**: Choose between a feature-rich Streamlit interface or a clean Gradio interface to interact with the system.
* **Database Management**: Includes command-line utilities to view database stats, list documents, test searches, and clear the knowledge base.
* **Local & Private**: Runs entirely on your local machine. Your documents and queries are never sent to the cloud, ensuring 100% privacy.

## ⚙️ Technology Stack

* **LLM**: Ollama (`mistral`) for answer synthesis.
* **Embeddings**: Ollama (`nomic-embed-text`) for document chunk vectorization.
* **Vector Database**: ChromaDB for efficient similarity search and storage.
* **Framework**: LangChain for orchestrating the RAG pipeline.
* **Frontend**: Streamlit and Gradio for the interactive user interfaces.

## 🔧 Setup and Installation

### Prerequisites

1.  **Python 3.9+**: Ensure you have a modern version of Python installed.
2.  **Ollama**: You must have Ollama installed and running. You can download it from [ollama.com](https://ollama.com).

### Installation Steps

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/rag-search-engine.git](https://github.com/your-username/rag-search-engine.git)
    cd rag-search-engine
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install the required Python packages:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Pull the necessary Ollama models:**
    ```bash
    ollama pull mistral
    ollama pull nomic-embed-text
    ```

## 🚀 Usage

### 1. Populate the Knowledge Base

First, you need to add your PDF documents to the vector database.

* Create a `data` directory in the root of the project.
* Place any PDF files you want to query inside the `data` directory.
* Run the `populate_database.py` script:
    ```bash
    python populate_database.py
    ```
    This will process the PDFs, create embeddings, and store them in a `chroma` directory. To reset and re-populate the database, use the `--reset` flag:
    ```bash
    python populate_database.py --reset
    ```

### 2. Launch a Web Interface

You can choose between two graphical interfaces. Run one of the following commands from your terminal:

* **To launch the Streamlit app:**
    ```bash
    streamlit run app.py
    ```
* **To launch the Gradio app:**
    ```bash
    python app_gradio.py
    ```
Once launched, you can use the interface to upload new documents or ask questions about the documents already in your knowledge base.

### 3. Use the Command-Line Interface (CLI)

You can also interact with the system directly from the command line.

* **To ask a question:**
    ```bash
    python query_data.py "Your question here?"
    ```

* **To manage the database with `chroma_utils.py`:**
    ```bash
    # Show database statistics
    python chroma_utils.py stats

    # List all documents in the DB
    python chroma_utils.py list

    # Test a search query
    python chroma_utils.py search "your search query"

    # Clear the entire database (use with caution!)
    python chroma_utils.py clear
    ```

## 📂 Project Structure
.
├── 📂 data/                   # (Create this folder) Your PDF documents go here
├── 📜 .gitignore              # Files and folders to be ignored by Git
├── 🐍 app.py                  # Main Streamlit web application
├── 🐍 app_gradio.py           # Alternative Gradio web application
├── 🐍 chroma_utils.py         # CLI tool for managing the ChromaDB database
├── 🐍 get_embedding_function.py # Configures the embedding model (Ollama)
├── 🐍 populate_database.py    # Ingests PDFs into ChromaDB
├── 🐍 query_data.py           # Core logic for the RAG query process (CLI)
├── 📝 README.md                # Project documentation
├── 📄 requirements.txt        # Python package dependencies
└── 🧪 test_rag.py             # Pytest script for evaluating the RAG pipeline
